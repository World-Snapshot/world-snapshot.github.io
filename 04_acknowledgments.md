## Acknowledgments

We thank all our colleagues and collaborators for their valuable feedback and discussions. This work was supported in part by NSF grants, and we gratefully acknowledge the [open-source code and various resources](https://github.com/World-Snapshot/wsg) used for this project. Special thanks to the research community for their constructive feedback during the development of this work.

**Additional Declaration & To the Media:** Our work is an exploration aimed at an ideal world model, following the principles of "conformal symmetry + encoding all information to the boundary", using our defined Wave Generative Models (or Wave-based Model) as the primary structure.

- All work that conforms to our definition, approximation, or derivative with the goal of exploring ideal world models will be called World Snapshot Model series/family. Just as deep learning evolved from machine learning yet is different. We are intentionally establishing an independent research field/area distinct from all existing claimed world models (video generation, hybrid Agents, VLMs, robotics, and new image generation architectures, etc). So we will be the "World Snapshot Model (WSM)" research area. *Interactive physical image and scene reconstruction, are our prototype work, although they typically only meet [3/9 of our standards](https://world-snapshot.github.io/doc/index.html?page=S5_blogs/00_world_model.md#definition) and [4.5/11 of our features](https://github.com/World-Snapshot/WaveGen#abstract).*
- 2-4D models using our defined wave generation mechanism (such as recording 3D information core space by special shape math functions), with the goal of exploring generative models, will be called or belong to Wave Generative Models (or Wave-based Model).
- The wave mainly refers to the special shape math waves in space (not a collection of individual particle clouds, but a continuous function composed of multiple functions that can be infinitely differentiated and represents a reality probability distribution). Creating a probability distribution composed of functions to correspondingly manipulate the richly informative surface of the world (world snapshot) like a shadow is the core concept of the wave generation model.
- The process of generating content not from random pixels/noise, but through meaningful information tensors (shapes, spatial information, planar structures), initializing a start with multi-dimensional information (It is generally more than the original model, for example, using image structures with 3D information to assist ordinary image generation models), is called ["Sen Fang Initialization"](https://github.com/World-Snapshot/Sen-Fang-Initialization), which can be applied to a broader range of AI models. Just as an internal combustion engine needs an igniter, "Sen Fang Initialization" generally uses lighter techniques to generate a meaningful initial input.
- The Wave Generation Method (WaveGen) and the World Snapshot Models (WSMs) address distinct, orthogonal dimensions of the problem, yet they remain fundamentally intertwinedâ€”much like the double helix of DNA. It is precisely because they handle different aspects of the system that these two approaches are inherently interdependent. They should be viewed as components of a naturally unified architecture.

Finally, in previous work, there is a high probability that there are methods similar to ours or some kind of variations. Moreover, different implementation paths are also likely to achieve similar or the same results as ours. Therefore, we can only hope that this work can provide a little inspiration.

**Limitations:** Due to the limitation of computing resources as non-industrial team, the project is still at an [initial stage](https://world-snapshot.github.io/doc/index.html?page=S6_materials/04_questions.md#future-work-full-roadmap) and has not fully achieved its optimal performance:
- For now, it is not a perfect project. Many aspects of it adopt different approaches and methods from existing models, which means it has to start from scratch<sup class="footnote" data-note="On the surface, those who are indifferent to the methodology might even consider this to be the 'weakest' world models. However, we merely wish to remind you that it is not an ordinary video generation model.">12</sup>. For instance, its ability to generate wave space is quite weak (currently, only dynamic simple multi-object generation is possible), which is caused by the need for new data processing in this new method. It should not be compared with some so-called video generation models (as we know, they have another name), but rather should be compared with some 3D model/scenario generation work (the current best is generating multiple static houses). 
- The resources we consume are only 1/1k, 1/10k or even less, than that of large companies. We only focus on the upper limit and what can be achieved: for instance, without any annotations, merely through 3D data training, 30 to 500 values can be used to represent the 3D shape in a single frame<sup class="footnote" data-note="The key points of the skeleton require 400 values (with some loss); 3DAvatar/SMPL requires similar rotation angle values + tens of thousands of vertices; single-frame data such as point clouds, Gaussians, and images require 100,000 values. And we can obtain a nearly lossless 3D shape in just 0.1 seconds without losing too much, and it is compatible with the physics engine. This means that perhaps CNNs can generate dynamic ultra-long Mesh models as well.">13</sup>. The demand is reduced to 1/10 or even 1/10,000, indicating that the existing method/big company can do much more by using our theory. This is where the new significance lies. It is more like a [DDPM](https://arxiv.org/abs/2006.11239) type of work<sup class="footnote" data-note="Even not SD1.5. Only when the mathematical functions in the core space can perfectly and losslessly fit any shape in reality would it be considered relatively mature, such as the shape of a palm.">14</sup> that requires improvement. 
- At present, our core space only supports the generation and reconstruction of simple shapes. So, more experiments and developments are needed. Please stay tuned.

This project (including multiple warehouses, concepts, code, and models) will continue to be updated and developed. The subsequent results will also be completely open-source or released in the form of articles.

**Q&As:** More information will be continuously updated to [this link](https://world-snapshot.github.io/doc/index.html?page=S6_materials/04_questions.md). If does not exist, please submit an issue.

**Announcement:** The selected News will be updated on the Github organization [introduction page](https://github.com/World-Snapshot) of the project, and the complete news will be updated on the [corresponding page](https://world-snapshot.github.io/doc/index.html?page=S6_materials/01_news.md) of the document.